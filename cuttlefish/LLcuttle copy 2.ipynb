{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import scipy as sp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleandataLL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[[\"sub\", \"lessonType\", \"cue_text\", \"answer\", \"reactionTime\", \"correct\", \"givenResponse\", \"repetition\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'sub': 'participant', 'lessonType':'condition', 'cue_text':'cue', 'answer':'target','givenResponse':'response', 'reactionTime':'rt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column values\n",
    "df['condition'] = np.where(df['condition'].str.strip() == 'Recall', 2, 1)\n",
    "df['correct'] = np.where(df['correct'] == True, 1, 0)\n",
    "df['rt'] = df['rt']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>condition</th>\n",
       "      <th>cue</th>\n",
       "      <th>target</th>\n",
       "      <th>rt</th>\n",
       "      <th>correct</th>\n",
       "      <th>response</th>\n",
       "      <th>repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub01</td>\n",
       "      <td>2</td>\n",
       "      <td>Zawadi</td>\n",
       "      <td>Reward</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub01</td>\n",
       "      <td>2</td>\n",
       "      <td>Bustani</td>\n",
       "      <td>Garden</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>1</td>\n",
       "      <td>broom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub01</td>\n",
       "      <td>2</td>\n",
       "      <td>Kitambaa</td>\n",
       "      <td>Fabric</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>cloud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub01</td>\n",
       "      <td>2</td>\n",
       "      <td>Dini</td>\n",
       "      <td>Religion</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1</td>\n",
       "      <td>religion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub01</td>\n",
       "      <td>2</td>\n",
       "      <td>Sumu</td>\n",
       "      <td>Poison</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>1</td>\n",
       "      <td>poison</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant  condition       cue    target      rt  correct  response  \\\n",
       "0       sub01          2    Zawadi    Reward  1577.0        1       dog   \n",
       "1       sub01          2   Bustani    Garden  4337.0        1     broom   \n",
       "2       sub01          2  Kitambaa    Fabric  1645.0        1     cloud   \n",
       "3       sub01          2      Dini  Religion  1156.0        1  religion   \n",
       "4       sub01          2      Sumu    Poison  1505.0        1    poison   \n",
       "\n",
       "   repetition  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(traces, time, decay):\n",
    "    \"\"\"Computes the activation of a memory given its history of retrievals\"\"\"\n",
    "    ftraces = [x for x in traces if x < time]\n",
    "    decay = max(0, decay)  # Allows no positive decay rates in equation \n",
    "    decay - min(decay, 5)\n",
    "    times = time - np.array(ftraces)\n",
    "    odds = times ** -decay\n",
    "    return np.log(np.sum(odds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boltzmann(options, values, temperature):\n",
    "    \"\"\"Returns a Boltzmann distribution of the probabilities of each option\"\"\"\n",
    "    temperature = max(temperature, 0.01) \n",
    "    vals = np.array(values)/temperature\n",
    "    #bvals = np.exp(vals)/np.sum(np.exp(vals))\n",
    "    bvals = np.exp(vals - np.max(vals)) / np.exp(vals - np.max(vals)).sum()\n",
    "    return dict(zip(options, bvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def responsetime(activation, ter, F=1, f=1):\n",
    "    return ter + F * np.exp(-f * activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import proxy_bypass\n",
    "def rtProb(rt, activation, s, ter):\n",
    "  \"\"\"Takes one parameter for noise, s, and outputs a probability distribution for response times\"\"\"\n",
    "  noise = np.linspace(-2, 2)\n",
    "  dist = sp.stats.logistic(0, ((math.pi**2)*s)/3)\n",
    "  rts = [responsetime((activation - x), ter) for x in noise]\n",
    "  prob = dist.pdf(noise)\n",
    "  rtprob = {rts[i]:prob[i]for i in range(len(noise))}\n",
    "  val = min(rtprob.keys(), key=lambda x: abs(x - (rt/1000)))\n",
    "  return rtprob[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLelabRT(alldata, ppt, rep, decay, temp, ter, mas = 1.6):\n",
    "    \"\"\"For each trial, calculate the probability of that response, sum the log likelihoods, and update the values\"\"\"\n",
    "    data = alldata[(alldata.participant == ppt) & (alldata.repetition == rep)]\n",
    "\n",
    "    # Sample min_count rows for each condition\n",
    "    sampled_1 = data[data['condition'] == 1].sample(n=25)\n",
    "    sampled_2 = data[data['condition'] == 2].sample(n=25)\n",
    "\n",
    "    # Combine the samples\n",
    "    data = pd.concat([sampled_1, sampled_2])\n",
    "\n",
    "    # create a list of error items\n",
    "    errors = data[data.condition == 1].cue.tolist()\n",
    "    # create a list of study items\n",
    "    study = data[data.condition == 2].cue.tolist()\n",
    "    \n",
    "    pos = 1\n",
    "    present = errors[:]\n",
    "    for i in range(len(errors)):\n",
    "      word = study[i]\n",
    "      present.insert(pos, word)\n",
    "      pos += 2\n",
    "\n",
    "    # make sure we have \"some\" data to move on\n",
    "    if len(present) >= 50:\n",
    "      # Create dict with word pairs\n",
    "      pairs = {}\n",
    "      for cue, target in zip(data.cue,data.target):\n",
    "        pairs[cue] = target\n",
    "      # also create a dict with errors\n",
    "      errorResp = dict()\n",
    "      for cue,response in zip(alldata[(alldata.participant == ppt) & (alldata.condition == 1) & (alldata.repetition == 0)].cue,\n",
    "                              alldata[(alldata.participant == ppt) & (alldata.condition == 1) & (alldata.repetition == 0)].response):\n",
    "        errorResp[cue] = response\n",
    "\n",
    "      # model learning phase, encode a single trace for each item: (idk what to set activation at)\n",
    "      DM = dict()\n",
    "      # for DM can we make a dictionary of dictionaries where big keys are cues, values are dictionary of target/\n",
    "      # possible responses and their activation\n",
    "      time = 0\n",
    "      for cue in present:\n",
    "        littleDM = {}\n",
    "        # make a set of all reponses given to a certain cue to be \"vocab for that cue\"\n",
    "        for response in set(alldata[alldata.cue == cue].response):\n",
    "          littleDM[response] = [0.001]\n",
    "        # add retrieval of error for error items\n",
    "        if cue in errorResp.keys():\n",
    "          error = errorResp[cue]\n",
    "          time +=5\n",
    "          littleDM[error] = [0.001, time]\n",
    "        # overwrite smaller activ of correct target to show task learning\n",
    "          time +=5\n",
    "          littleDM[pairs[cue]] = [0.001, time]\n",
    "\n",
    "        else:\n",
    "          time += 10\n",
    "          littleDM[pairs[cue]] = [0.001, time]\n",
    "\n",
    "        DM[cue] = littleDM\n",
    "      time += 300 # time for distractor phase\n",
    "\n",
    "\n",
    "      # model testing phase\n",
    "      LL = 0\n",
    "      for condition, cue, response, rt, feedback in zip(data.condition,\n",
    "                                    data.cue, \n",
    "                                    data.response, \n",
    "                                    data.rt, \n",
    "                                    data.correct):\n",
    "        # Calculate log likelihood of response- possible options are 19 random integers\n",
    "        # or correct associate\n",
    "        options = DM[cue].keys()\n",
    "        # create spreading activation additional error component given size of cue's dec mem\n",
    "        cueMem = len(DM[cue])\n",
    "        add = (mas - np.log((cueMem + 1)/2)) - (mas - np.log((cueMem + 1)/1))\n",
    "\n",
    "        # if error condition, add spreading activation\n",
    "        values = [(activation(DM[cue][opt], time, decay) + add) if condition == 1 else \n",
    "        activation(DM[cue][opt], time, decay) for opt in options]\n",
    "        prob = boltzmann(options, values, temp)[response]\n",
    "      \n",
    "        # now calculate response times:\n",
    "        if condition == 1:\n",
    "          resp_activation = activation(DM[cue][response], time, decay) + add\n",
    "        else: \n",
    "          resp_activation = activation(DM[cue][response], time, decay)\n",
    "\n",
    "        \n",
    "        prob_rt = rtProb(rt, resp_activation, temp, ter)\n",
    "        print(prob_rt)\n",
    "        # Sum up the LLs\n",
    "        # LL += (np.log(max(prob, 10e-10)) + np.log(max(prob_rt, 10e-10)))\n",
    "        LL += np.log(max(prob_rt, 10e-10))\n",
    "\n",
    "        # add time taken to responde\n",
    "        time += rt/1000\n",
    "    else:\n",
    "      LL = 0\n",
    "    return LL\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07446472084049492\n",
      "0.07591782870035427\n",
      "0.07471575050394451\n",
      "0.07446472084049492\n",
      "0.06938066766236886\n",
      "0.0721241220126985\n",
      "0.07549882664815326\n",
      "0.07596457568570096\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07127971677450015\n",
      "0.07251833954903393\n",
      "0.07446472084049492\n",
      "0.07584778011050178\n",
      "0.06988043632706319\n",
      "0.07596457568570099\n",
      "0.07389836349880202\n",
      "0.0721241220126985\n",
      "0.07563815067451198\n",
      "0.06938066766236886\n",
      "0.07289329429984732\n",
      "0.06938066766236886\n",
      "0.07446472084049492\n",
      "0.07515201002448926\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07251833954903393\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "-132.1264772538235\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07083048066308276\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07563815067451198\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07251833954903393\n",
      "0.06938066766236886\n",
      "0.07251833954903393\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07083048066308276\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "-133.19117341016076\n"
     ]
    }
   ],
   "source": [
    "print(LLelabRT(df, ppt='sub01', rep=0, decay=0.5, temp=1, ter=1))\n",
    "print(LLelabRT(df, ppt='sub01', rep=3, decay=0.5, temp=1, ter=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import proxy_bypass\n",
    "def rtProb2(rt, resp_activation, error_activation, condition, s, ter):\n",
    "  \"\"\"Takes one parameter for noise, s, and outputs a probability distribution for response times\"\"\"\n",
    "  noise = np.linspace(-2, 2)\n",
    "  dist = sp.stats.logistic(0, ((math.pi**2)*s)/3)\n",
    "  if condition == 1:\n",
    "    rts = [(responsetime((resp_activation - x), ter) + responsetime((error_activation - x), ter)) for x in noise]\n",
    "  else: \n",
    "    rts = [responsetime((resp_activation - x), ter) for x in noise]\n",
    "  prob = dist.pdf(noise)\n",
    "  rtprob = {rts[i]:prob[i]for i in range(len(noise))}\n",
    "  val = min(rtprob.keys(), key=lambda x: abs(x - (rt/1000)))\n",
    "  return rtprob[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLmedRT(alldata, ppt, rep, decay, temp, ter):\n",
    "    \"\"\"For each trial, calculate the probability of that response, sum the log likelihoods, and update the values\"\"\"\n",
    "    data = alldata[(alldata.participant == ppt) & (alldata.repetition == rep)]\n",
    "\n",
    "    # Sample min_count rows for each condition\n",
    "    sampled_1 = data[data['condition'] == 1].sample(n=25)\n",
    "    sampled_2 = data[data['condition'] == 2].sample(n=25)\n",
    "\n",
    "    # Combine the samples\n",
    "    data = pd.concat([sampled_1, sampled_2])\n",
    "\n",
    "    # create a list of error items\n",
    "    errors = data[data.condition == 1].cue.tolist()\n",
    "    # create a list of study items\n",
    "    study = data[data.condition == 2].cue.tolist()\n",
    "    \n",
    "    pos = 1\n",
    "    present = errors[:]\n",
    "    for i in range(len(errors)):\n",
    "      word = study[i]\n",
    "      present.insert(pos, word)\n",
    "      pos += 2\n",
    "\n",
    "    #check for some data\n",
    "    if len(present) >= 50:\n",
    "      # Create dict with word pairs\n",
    "      pairs = {}\n",
    "      for cue, target in zip(data.cue,data.target):\n",
    "        pairs[cue] = target\n",
    "      # also create a dict with errors\n",
    "      errorResp = dict()\n",
    "      for cue,response in zip(data[data.condition == 1].cue,data[data.condition == 1].response):\n",
    "        errorResp[cue] = response\n",
    "\n",
    "      # model learning phase, encode a single trace for each item: (idk what to set activation at)\n",
    "      DM = dict()\n",
    "      # for DM can we make a dictionary of dictionaries where big keys are cues, values are dictionary of target/\n",
    "      # possible responses and their activation\n",
    "      time = 0\n",
    "      step = 10 #time for learning each item\n",
    "      for cue in present:\n",
    "        littleDM = {}\n",
    "        # make a set of all reponses given to a certain cue to be \"vocab for that cue\"\n",
    "        for response in set(alldata[alldata.cue == cue].response):\n",
    "          littleDM[response] = [0.001]\n",
    "        # add retrieval of error for error items\n",
    "        if cue in errorResp.keys():\n",
    "          error = errorResp[cue]\n",
    "          time +=5\n",
    "          littleDM[error] = [0.001, time]\n",
    "        # overwrite smaller activ of correct target to show task learning\n",
    "          time +=5\n",
    "          littleDM[pairs[cue]] = [0.001, time]\n",
    "\n",
    "        else:\n",
    "          time += 10\n",
    "          littleDM[pairs[cue]] = [0.001, time]\n",
    "\n",
    "        DM[cue] = littleDM\n",
    "      time += 300 # time for distractor phase\n",
    "\n",
    "      # model testing phase\n",
    "      LL = 0\n",
    "      \n",
    "      for condition, cue, response, rt, feedback in zip(data.condition,\n",
    "                                    data.cue, \n",
    "                                    data.response, \n",
    "                                    data.rt, \n",
    "                                    data.correct):\n",
    "          # Calculate log likelihood of response- possible options are 19 random integers\n",
    "          # or correct associate\n",
    "          options = DM[cue].keys()\n",
    "\n",
    "          # calculate probability of retrieving given response\n",
    "          values = [activation(DM[cue][opt], time, decay) for opt in options]\n",
    "          prob1 = boltzmann(options, values, temp)[response]\n",
    "          \n",
    "          # probability of retrieving error memory\n",
    "          if condition == 1:\n",
    "            error = errorResp[cue]\n",
    "            prob2 = boltzmann(options, values, temp)[error]\n",
    "          else:\n",
    "            prob2 = 0\n",
    "          \n",
    "          # add response times calculations\n",
    "          # probability of given response time with\n",
    "          respAct = activation(DM[cue][response], time, decay)\n",
    "          if condition == 1:\n",
    "            error = errorResp[cue]\n",
    "            errorAct = activation(DM[cue][error], time, decay)\n",
    "            prob_rt = rtProb2(rt, respAct, errorAct, condition, temp, ter)\n",
    "          else:\n",
    "            errorAct = 0\n",
    "            prob_rt = rtProb2(rt, respAct, errorAct, condition, temp, ter)\n",
    "\n",
    "          # Sum up the LLs\n",
    "          # LL += (np.log(max((prob1 + prob2)/1.4, 10e-10)) + np.log(max(prob_rt, 10e-10)))\n",
    "          LL += np.log(max(prob_rt, 10e-10))\n",
    "          print(prob_rt)\n",
    "          # add time taken to responde\n",
    "          time += rt/1000   \n",
    "    else:\n",
    "      LL = 0     \n",
    "    return LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07127971677450015\n",
      "0.06988043632706319\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07127971677450015\n",
      "0.06938066766236886\n",
      "0.0721241220126985\n",
      "0.06938066766236886\n",
      "0.07324855457003711\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07251833954903393\n",
      "0.07083048066308276\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "-133.1882232340507\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07324855457003711\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.07289329429984732\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "0.06938066766236886\n",
      "-133.30371207570323\n"
     ]
    }
   ],
   "source": [
    "print(LLmedRT(df, ppt='sub01', rep=0, decay=0.5, temp=1, ter=1))\n",
    "print(LLmedRT(df, ppt='sub01', rep=2, decay=0.5, temp=1, ter=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vLLelab(array, data, ppt, rep):\n",
    "    \"\"\"Vector function of procedural log-likelihood\"\"\"\n",
    "    decay, temp, ter = array\n",
    "    return -1 * LLelabRT(data, ppt, rep, decay, temp, ter)\n",
    "\n",
    "\n",
    "def vLLmed(array, data, ppt, rep):\n",
    "    \"\"\"Vector function of procedural log-likelihood\"\"\"\n",
    "    decay, temp, ter = array\n",
    "    return -1 * LLmedRT(data, ppt, rep, decay, temp, ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub01 0\n",
      "Mediator\n",
      "sub01 1\n",
      "Mediator\n",
      "sub01 2\n",
      "Mediator\n",
      "sub01 3\n",
      "Mediator\n",
      "sub01 4\n",
      "Mediator\n",
      "sub01 5\n",
      "Mediator\n",
      "sub01 6\n",
      "Mediator\n",
      "sub01 7\n",
      "Mediator\n",
      "sub01 8\n",
      "Mediator\n",
      "sub01 9\n",
      "Mediator\n",
      "sub02 0\n",
      "Mediator\n",
      "sub02 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bridget Leonard\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1983: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediator\n",
      "sub02 2\n",
      "Mediator\n",
      "sub02 3\n",
      "Mediator\n",
      "sub02 4\n"
     ]
    }
   ],
   "source": [
    "DO_ALL = True\n",
    "dataframe = []\n",
    "\n",
    "if DO_ALL:\n",
    "    for ppt in df.participant.unique():\n",
    "        for rep in range(10):\n",
    "            print(ppt, rep)\n",
    "            data = df[(df.participant == ppt) & (df.repetition == rep)]\n",
    "            edecay, etemp, eter = opt.minimize(vLLelab, x0 = [0.5, 1, 1], args=(data, ppt, rep), method = \"Powell\", bounds=[[0.01, 2], [0, 2], [0.1, 2]]).x\n",
    "            llelab = LLelabRT(df, ppt, rep, edecay, etemp, eter)\n",
    "                \n",
    "            mdecay, mtemp, mter = opt.minimize(vLLmed, x0 = [0.5, 1, 1], args=(data, ppt, rep), method = \"Powell\", bounds=[[0.01, 2], [0, 2], [0.1, 2]]).x\n",
    "            llmed = LLmedRT(df, ppt, rep, mdecay, mtemp, mter)\n",
    "                \n",
    "            best = \"Mediator\"\n",
    "            if llelab > llmed:\n",
    "                best = \"Elaborative\"\n",
    "\n",
    "            print(best)    \n",
    "            diff = llmed - llelab\n",
    "                \n",
    "            row = [ppt, rep, edecay, etemp, eter, llelab, mdecay, mtemp, mter, llmed, best, diff]\n",
    "                \n",
    "            dataframe += [row]\n",
    "\n",
    "        result = pd.DataFrame(dataframe, columns=[\"Participant\", \"Presentation\", \"elab.decay\", \"elab.temp\", \"elab.ter\", \"elab.LL\", \"med.decay\", \"med.temp\", \"med.ter\", \"med.LL\", \"best.model\", \"diff.LL\"])\n",
    "        result.to_csv('LL_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
